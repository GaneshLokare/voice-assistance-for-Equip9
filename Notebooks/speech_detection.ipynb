{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff86ff53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from prettytable import PrettyTable\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from keras.layers import Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17dc9639",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dataframe(name=df_audio) with two columns(path, label).   \n",
    "#Eg: 0_jackson_0 --> 0 (label)\n",
    "#0_jackson_43 --> 0 (label)\n",
    "all_files = os.listdir('new')\n",
    "df_audio = pd.DataFrame()\n",
    "df_audio['path'] = ['new/' + ele for ele in all_files]\n",
    "df_audio['target'] = [ele.split(' ')[0] for ele in all_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25fe03c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 581 entries, 0 to 580\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   path    581 non-null    object\n",
      " 1   target  581 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 9.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#info\n",
    "df_audio.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe9152b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new/bulldozer Bulldoze zh-cn.mp3</td>\n",
       "      <td>bulldozer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>new/bulldozer Bulldoze zh-tw.mp3</td>\n",
       "      <td>bulldozer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new/bulldozer Bulldozer af.mp3</td>\n",
       "      <td>bulldozer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>new/bulldozer Bulldozer ar.mp3</td>\n",
       "      <td>bulldozer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>new/bulldozer Bulldozer bg.mp3</td>\n",
       "      <td>bulldozer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               path     target\n",
       "0  new/bulldozer Bulldoze zh-cn.mp3  bulldozer\n",
       "1  new/bulldozer Bulldoze zh-tw.mp3  bulldozer\n",
       "2    new/bulldozer Bulldozer af.mp3  bulldozer\n",
       "3    new/bulldozer Bulldozer ar.mp3  bulldozer\n",
       "4    new/bulldozer Bulldozer bg.mp3  bulldozer"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print few rows\n",
    "df_audio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fe9ea47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "path      581\n",
       "target      5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check uniques\n",
    "df_audio.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d42a6133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bulldozer     118\n",
       "excavators    116\n",
       "JCB           116\n",
       "roller        116\n",
       "crane         115\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check unique values in target column\n",
    "df_audio['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc9b9a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create an instance of LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "le.fit(df_audio['target'])\n",
    "\n",
    "# Transform the 'target' column using the fitted LabelEncoder\n",
    "df_audio['label'] = le.transform(df_audio['target'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31a076b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    118\n",
       "3    116\n",
       "0    116\n",
       "4    116\n",
       "2    115\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoded values\n",
    "df_audio['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb7239c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffling the dataframe\n",
    "df_audio = shuffle(df_audio, random_state=33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e6589e",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "All files are in the \"mp3\" format. We will read those raw data files using the librosa library</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b413dc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 22050\n",
    "def load_wav(x, get_duration=True):\n",
    "    '''This will return the array values of audio with sampling rate of 22050 and Duration'''\n",
    "    #loading the wav file with sampling rate of 22050\n",
    "    samples, sample_rate = librosa.load(x, sr=22050)\n",
    "    if get_duration:\n",
    "        duration = librosa.get_duration(y = samples, sr = sample_rate)\n",
    "        return [samples, duration]\n",
    "    else:\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0db54e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, durations = [],[]\n",
    "\n",
    "\n",
    "for ele in df_audio['path'].values:\n",
    "    try:\n",
    "        sample, duration = load_wav(str(ele))\n",
    "        samples.append(samples)\n",
    "        durations.append(duration)\n",
    "    except:\n",
    "        print(ele)\n",
    "\n",
    "processed = pd.DataFrame({'raw_data' : samples, 'duration' : durations})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5b2eae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(581, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7204825",
   "metadata": {},
   "source": [
    "### Identifying optimal padding length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1b12e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting the histogram of the duration for trian\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.hist(processed.duration)\n",
    "plt.xlabel('Duration')\n",
    "plt.title('Histogram of Durations of audios')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2266d1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th percentile is 0.4963265306122449\n",
      "10th percentile is 0.8640362811791383\n",
      "20th percentile is 0.96\n",
      "30th percentile is 1.0320181405895692\n",
      "40th percentile is 1.1280272108843536\n",
      "50th percentile is 1.2\n",
      "60th percentile is 1.2960090702947846\n",
      "70th percentile is 1.3680272108843536\n",
      "80th percentile is 1.4640362811791383\n",
      "90th percentile is 1.56\n",
      "100th percentile is 2.8080272108843536\n"
     ]
    }
   ],
   "source": [
    "#print 0 to 100 percentile values with step size of 10 for train data duration. \n",
    "for i in range(0,11,1):\n",
    "    print(f\"{i*10}th percentile is {np.percentile(processed.duration.values, i*10)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c76eb6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90th percentile is 1.56\n",
      "91th percentile is 1.5840362811791384\n",
      "92th percentile is 1.5840362811791384\n",
      "93th percentile is 1.6080272108843536\n",
      "94th percentile is 1.6560090702947845\n",
      "95th percentile is 1.68\n",
      "96th percentile is 1.7424217687074808\n",
      "97th percentile is 1.8\n",
      "98th percentile is 1.8816145124716548\n",
      "99th percentile is 2.1648072562358287\n",
      "100th percentile is 2.8080272108843536\n"
     ]
    }
   ],
   "source": [
    "##print 90 to 100 percentile values with step size of 1. \n",
    "for i in range(0,11,1):\n",
    "    print(f\"{i+90}th percentile is {np.percentile(processed.duration.values, i+90)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd0eb3a",
   "metadata": {},
   "source": [
    "<pre>Based on our analysis 99 percentile values are less than 0.8sec so we will limit maximum length of X_train_processed and X_test_processed to 0.8 sec.\n",
    "\n",
    "While loading the audio files, we are using sampling rate of 22050 so one sec will give array of length 22050. so, our maximum length is 2*22050 = 45000\n",
    "\n",
    "Padding with Zero if length of sequence is less than 17640 else truncating the number. \n",
    "\n",
    "Also creating a masking vector for train and test. \n",
    "\n",
    "Masking vector value = 1 if it is real value, 0 if it is pad value. Masking vector data type will be bool.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c860e8d9",
   "metadata": {},
   "source": [
    "## Generate Raw audio waveforms with data augmentation\n",
    "<pre>\n",
    "We have small dataset, thus we will perform augmentation on audios to improve the model performance. \n",
    "There are two types of augmentation:\n",
    "1. time stretching - Time stretching either increases or decreases the length of the file. For time stretching we move the file 30% faster or slower\n",
    "2. pitch shifting - pitch shifting moves the frequencies higher or lower. For pitch shifting we shift up or down one half-step.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3328cebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## generating augmented data. \n",
    "def generate_augmented_data(file_path):\n",
    "    augmented_data = []\n",
    "    samples = load_wav(file_path,get_duration=False)\n",
    "    for time_value in [0.7, 1, 1.3]:\n",
    "        for pitch_value in [-1, 0, 1]:\n",
    "            time_stretch_data = librosa.effects.time_stretch(samples, rate=time_value)\n",
    "            final_data = librosa.effects.pitch_shift(time_stretch_data, sr=sample_rate, n_steps=pitch_value)\n",
    "            augmented_data.append(final_data)\n",
    "    return augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc52dd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_audio.path, df_audio.label, stratify = df_audio.label, \n",
    "                                                    test_size = 0.2, random_state = 32321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d67ece3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate augmented data\n",
    "train_aug_data = []\n",
    "train_labels = []\n",
    "\n",
    "for path, label in zip(X_train.values, y_train.values):\n",
    "    aug_data = generate_augmented_data(path)\n",
    "    n_augmented = len(aug_data)\n",
    "    train_aug_data.extend(aug_data)\n",
    "    train_labels.extend([str(label)]*n_augmented)\n",
    "\n",
    "X_train_processed = pd.DataFrame({'raw_data' : train_aug_data, 'label' : train_labels})\n",
    "\n",
    "test_data = []\n",
    "for path in X_test.values:\n",
    "    test_data.append(load_wav(path, get_duration = False))\n",
    "\n",
    "X_test_processed = pd.DataFrame({'raw_data' : test_data, 'label' : y_test.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "955b590a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4176 entries, 0 to 4175\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   raw_data  4176 non-null   object\n",
      " 1   label     4176 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 65.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "X_train_processed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e934c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_data</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[4.7327993e-07, 5.1230535e-07, 4.6442165e-07, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-2.0015218e-09, -3.8409333e-09, -3.1627836e-0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1.0629081e-08, 1.0777184e-08, 1.0950133e-08, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-2.3022065e-07, -2.5660603e-07, -2.2576822e-0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-3.4089363e-12, -2.714116e-12, -3.5769e-12, 2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_data label\n",
       "0  [4.7327993e-07, 5.1230535e-07, 4.6442165e-07, ...     1\n",
       "1  [-2.0015218e-09, -3.8409333e-09, -3.1627836e-0...     1\n",
       "2  [1.0629081e-08, 1.0777184e-08, 1.0950133e-08, ...     1\n",
       "3  [-2.3022065e-07, -2.5660603e-07, -2.2576822e-0...     1\n",
       "4  [-3.4089363e-12, -2.714116e-12, -3.5769e-12, 2...     1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print few rows\n",
    "X_train_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c49d300c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#padding the sequences\n",
    "X_train_pad_seq = pad_sequences(X_train_processed.raw_data, maxlen = 45000,\n",
    "                                dtype = 'float32', padding = 'post', \n",
    "                                truncating = 'post')\n",
    "X_test_pad_seq = pad_sequences(X_test_processed.raw_data, maxlen = 45000, \n",
    "                               dtype = 'float32', padding = 'post', \n",
    "                               truncating = 'post')\n",
    "\n",
    "y_train = X_train_processed.label.values.astype('int')\n",
    "y_test = X_test_processed.label.values.astype('int')\n",
    "\n",
    "X_train_mask = X_train_pad_seq != 0\n",
    "X_test_mask = X_test_pad_seq != 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5168b1",
   "metadata": {},
   "source": [
    "## Using Spectrogram data with data augmentation\n",
    "<pre>\n",
    "We can use librosa to convert raw data into spectrogram. A spectrogram is a visual way of representing the signal strength, or “loudness”, of a signal over time at various frequencies present in a particular waveform. \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84f8bd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_spectrogram(raw_data):\n",
    "    '''converting to spectrogram'''\n",
    "    spectrum = librosa.feature.melspectrogram(y=raw_data, sr=sample_rate, n_mels=64)\n",
    "    logmel_spectrum = librosa.power_to_db(S=spectrum, ref=np.max)\n",
    "    return logmel_spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2f9c187",
   "metadata": {},
   "outputs": [],
   "source": [
    "##use convert_to_spectrogram and convert every raw sequence in X_train_pad_seq and X_test_pad_seq.\n",
    "## save those all in the X_train_spectrogram and X_test_spectrogram ( These two arrays must be numpy arrays)\n",
    "X_train_spectrogram = []\n",
    "for ele in X_train_pad_seq:\n",
    "    logmel = convert_to_spectrogram(ele)\n",
    "    X_train_spectrogram.append(logmel)\n",
    "X_train_spectrogram = np.array(X_train_spectrogram)\n",
    "\n",
    "X_test_spectrogram = []\n",
    "for ele in X_test_pad_seq:\n",
    "    logmel = convert_to_spectrogram(ele)\n",
    "    X_test_spectrogram.append(logmel)\n",
    "X_test_spectrogram = np.array(X_test_spectrogram)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3ae34a",
   "metadata": {},
   "source": [
    "## Model definition and training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a873bda0",
   "metadata": {},
   "source": [
    "### Custom Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61490d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1ScoreCB(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, train_data, test_data):\n",
    "        super().__init__()\n",
    "        self.train_data = train_data\n",
    "        self.test_data = test_data\n",
    "        self.history = {}\n",
    "        self.history['val_f1_score'] = []\n",
    "  \n",
    "    def on_epoch_end(self, epochs, logs = {}):\n",
    "        train_preds = np.argmax(self.model.predict(self.train_data[0]), axis = -1)\n",
    "        train_f1_score = f1_score(self.train_data[1], train_preds, average='micro')\n",
    "        train_f1_score = np.round(train_f1_score, 4)\n",
    "\n",
    "        test_preds = np.argmax(self.model.predict(self.test_data[0]), axis = -1)\n",
    "        test_f1_score = f1_score(self.test_data[1], test_preds, average='micro')\n",
    "        test_f1_score = np.round(test_f1_score, 4)\n",
    "        self.history['val_f1_score'].append(test_f1_score)\n",
    "\n",
    "        print(f\" - f1_score: {train_f1_score} - val_f1_score: {test_f1_score}\")\n",
    "\n",
    "        writer1 = tf.summary.create_file_writer(logdir + '/train_f1_score')\n",
    "        writer2 = tf.summary.create_file_writer(logdir + '/validation_f1_score')\n",
    "        \n",
    "        #writing to tensoboard\n",
    "        with writer1.as_default():\n",
    "            tf.summary.scalar('F1_Score', train_f1_score, step=epochs)\n",
    "        writer1.flush()\n",
    "\n",
    "        with writer2.as_default():\n",
    "            tf.summary.scalar('F1_Score', test_f1_score, step=epochs)\n",
    "        writer2.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0475bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 64, 88)]          0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64, 512)           1230848   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64, 512)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64, 256)           787456    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64, 256)           0         \n",
      "                                                                 \n",
      " tf.math.reduce_mean (TFOpLa  (None, 64)               0         \n",
      " mbda)                                                           \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               33280     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 3078      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,054,662\n",
      "Trainable params: 2,054,662\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define model architecture\n",
    "tf.keras.backend.clear_session()\n",
    "inp = Input(shape=(64, 88,))\n",
    "x = LSTM(512, return_sequences=True)(inp)\n",
    "x = Dropout(0.2)(x)\n",
    "x = LSTM(256, return_sequences=True)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = tf.math.reduce_mean(x, axis=-1)\n",
    "x = Dense(512, activation='relu', kernel_initializer='he_normal')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "out = Dense(6, activation='softmax', kernel_initializer='glorot_normal')(x)\n",
    "\n",
    "model = Model(inputs=inp, outputs=out)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14fd6655",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ERROR: Could not find `tensorboard`. Please ensure that your PATH\n",
       "contains an executable `tensorboard` program, or explicitly specify\n",
       "the path to a TensorBoard binary by setting the `TENSORBOARD_BINARY`\n",
       "environment variable."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#log training\n",
    "!rm -rf ./logs/\n",
    "import datetime\n",
    "\n",
    "logdir = os.path.join('logs', datetime.datetime.now().strftime('%Y%m%d-%H%M%S'))\n",
    "\n",
    "%tensorboard --logdir $logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "044e69ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "131/131 [==============================] - 145s 1s/step\n",
      "4/4 [==============================] - 4s 1s/step\n",
      " - f1_score: 0.7004 - val_f1_score: 0.735\n",
      "66/66 [==============================] - 501s 7s/step - loss: 1.2602 - val_loss: 0.8268\n",
      "Epoch 2/15\n",
      "131/131 [==============================] - 146s 1s/step\n",
      "4/4 [==============================] - 4s 679ms/step\n",
      " - f1_score: 0.8448 - val_f1_score: 0.8291\n",
      "66/66 [==============================] - 471s 7s/step - loss: 0.7106 - val_loss: 0.5219\n",
      "Epoch 3/15\n",
      "131/131 [==============================] - 153s 1s/step\n",
      "4/4 [==============================] - 4s 680ms/step\n",
      " - f1_score: 0.8429 - val_f1_score: 0.8034\n",
      "66/66 [==============================] - 476s 7s/step - loss: 0.5157 - val_loss: 0.4904\n",
      "Epoch 4/15\n",
      "131/131 [==============================] - 155s 1s/step\n",
      "4/4 [==============================] - 4s 786ms/step\n",
      " - f1_score: 0.8269 - val_f1_score: 0.812\n",
      "66/66 [==============================] - 481s 7s/step - loss: 0.4675 - val_loss: 0.6056\n",
      "Epoch 5/15\n",
      "131/131 [==============================] - 154s 1s/step\n",
      "4/4 [==============================] - 4s 1s/step\n",
      " - f1_score: 0.8805 - val_f1_score: 0.906\n",
      "66/66 [==============================] - 485s 7s/step - loss: 0.4902 - val_loss: 0.3617\n",
      "Epoch 6/15\n",
      "131/131 [==============================] - 166s 1s/step\n",
      "4/4 [==============================] - 5s 1s/step\n",
      " - f1_score: 0.8767 - val_f1_score: 0.8632\n",
      "66/66 [==============================] - 530s 8s/step - loss: 0.3919 - val_loss: 0.3933\n",
      "Epoch 7/15\n",
      "131/131 [==============================] - 170s 1s/step\n",
      "4/4 [==============================] - 4s 922ms/step\n",
      " - f1_score: 0.8918 - val_f1_score: 0.8974\n",
      "66/66 [==============================] - 526s 8s/step - loss: 0.4236 - val_loss: 0.3234\n",
      "Epoch 8/15\n",
      "131/131 [==============================] - 166s 1s/step\n",
      "4/4 [==============================] - 5s 1s/step\n",
      " - f1_score: 0.8762 - val_f1_score: 0.8718\n",
      "66/66 [==============================] - 527s 8s/step - loss: 0.3368 - val_loss: 0.3497\n",
      "Epoch 9/15\n",
      "131/131 [==============================] - 167s 1s/step\n",
      "4/4 [==============================] - 5s 1s/step\n",
      " - f1_score: 0.8827 - val_f1_score: 0.8974\n",
      "66/66 [==============================] - 529s 8s/step - loss: 0.3744 - val_loss: 0.2923\n",
      "Epoch 10/15\n",
      "131/131 [==============================] - 168s 1s/step\n",
      "4/4 [==============================] - 5s 1s/step\n",
      " - f1_score: 0.9306 - val_f1_score: 0.9145\n",
      "66/66 [==============================] - 530s 8s/step - loss: 0.3188 - val_loss: 0.2144\n",
      "Epoch 11/15\n",
      "131/131 [==============================] - 168s 1s/step\n",
      "4/4 [==============================] - 5s 1s/step\n",
      " - f1_score: 0.9179 - val_f1_score: 0.9316\n",
      "66/66 [==============================] - 535s 8s/step - loss: 0.3012 - val_loss: 0.2126\n",
      "Epoch 12/15\n",
      "131/131 [==============================] - 169s 1s/step\n",
      "4/4 [==============================] - 5s 978ms/step\n",
      " - f1_score: 0.9392 - val_f1_score: 0.9487\n",
      "66/66 [==============================] - 536s 8s/step - loss: 0.2704 - val_loss: 0.2108\n",
      "Epoch 13/15\n",
      "131/131 [==============================] - 172s 1s/step\n",
      "4/4 [==============================] - 5s 1s/step\n",
      " - f1_score: 0.9193 - val_f1_score: 0.9231\n",
      "66/66 [==============================] - 540s 8s/step - loss: 0.2688 - val_loss: 0.2534\n",
      "Epoch 14/15\n",
      "131/131 [==============================] - 170s 1s/step\n",
      "4/4 [==============================] - 5s 1s/step\n",
      " - f1_score: 0.9181 - val_f1_score: 0.8974\n",
      "66/66 [==============================] - 542s 8s/step - loss: 0.2591 - val_loss: 0.2716\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17051f788e0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile and train model\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(0.0005), loss = 'sparse_categorical_crossentropy')\n",
    "cb = [tf.keras.callbacks.TensorBoard(logdir, histogram_freq = 1, write_graph = True),\n",
    "      F1ScoreCB((X_train_spectrogram, y_train), (X_test_spectrogram, y_test)),\n",
    "      tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', min_delta = 0.005, patience = 4)]\n",
    "\n",
    "model.fit(X_train_spectrogram, y_train, validation_data = (X_test_spectrogram, y_test),\n",
    "           batch_size = 64, epochs = 15, callbacks = cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "41401f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to a file\n",
    "model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
